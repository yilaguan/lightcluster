In addition to README.md.

6. Common names of variables:

- 'n_vertex' --- amount of vertex
- 'n_edges' --- amount of edges
- 'n_clusters' --- amount of clusters
- 'edge_list' --- list of edges, always weighted (if graph is unweighted, then weight = 1), e.g. [[0, 1, 0.5], [0, 2, 1], [1, 3, 100], ...]
- 'lbls' --- list of labels with length of 'n_vertex', i-th vertex belongs to cluster lbl[i], e.g. [0, 0, 0, 1, 1, 1, 0, 2, 0, 2, ...]; 'lbls_true' for 
             ground-truth (only for non-ovrlapping communities)
- 'clrs' --- list of clusters, i-th element of list contains vertices that belongs to i-th cluster, e.g. [(0,1,2,3), (0,2,4), (4), ...]; 'clrs_true' for
             ground-truth (for overlapping communities as well as for non_overlapping)

- 'algorithms' --- list of strings, every string means some algorithm
- 'datasets' --- list of strings, every string means some dataset
- 'result' --- dictionary with keys ['algorithm', 'dataset', 'metric']

7. Functions:
---------------------------------------------------------------------------------------------------
	*load_data.py

	  - download_graph
	    Parameter: 'filename'
	      in this file graph should be described in following  format:
	      "n_vertex n_edges
	       vertex11 vertex12 weight1
	       vertex21 vertex22 weight2
	       vertex31 vertex32 weight3
	       ..."
	       or
	      "n_vertex n_edges
	       vertex11 vertex12
	       vertex21 vertex22
	       vertex31 vertex32
	       ..."
	    Returns:  pair of 'n_vertex', 'edge_list'

	  - download_labels
	    Parameter: 'filename'
	      in this file labels should be described in following  format:
	      "0
	       0
	       1
	       1
	       0
	       2
	       ..."
	      i-th row corresponds to label of i-th vertex
	    Returns:  'labels'

	  - download_clusters
	    Parameter:  'filename'
	      in this file clusters should be described in following  format:
	      "0 1 2 3
	       0 2 4
	       4
	       ..."
	      i-th row corresponds to i-th cluster and contains vertices of this cluster
	    Return:  'clusters'
    
    - write_labels
      Parameters: 'algorithm', 'dataset', 'labels'
        creates file with labels
    
    - write_clusters
      Parameters: 'algorithm', 'dataset', 'clusters'
        creates file with clusters
    
    - write_result
      Parameters: 'algorithms', 'datasets', 'result', 'filename'
        print the table of result in file with name 'filename'
---------------------------------------------------------------------------------------------------
    *model_builder.py

      - clustering
        Necessary parameters:
          algorithm: 'Spectral', 'SCAN', 'GreedyNewman', 'Walktrap', 'LPA', 'CFinder', 'Clauset-Newman', 'Bigclam' 
          'n_vertex'
          'edge_list' 
          'n_clusters' 
          'neighbours_threshold' 
          'similarity_threshold' 
          'n_steps'
          'clique_size'
        Returns:
          'labels', 'clusters' and 'execution time'

      - independent_clustering
        Necessary parameters: 
          algorithm: 'Spectral', 'SCAN', 'GreedyNewman', 'Walktrap', 'LPA', 'CFinder', 'Clauset-Newman', 'Bigclam'
          'n_vertex'
          'edge_list'
        Additional parameters:
          'n_clusters'
          'neighbours_threshold'
          'similarity_threshold'
          'n_steps'
          'clique_size'
        Returns:
          'labels', 'clusters' and 'execution time'

      - compute_spectral_clustering
        Necessary parameters: 
          'n_vertex'
          'edge_list'
          'n_clusters'
        Returns:
          'labels', 'clusters' and 'execution time'
       
      - compute_scan
        Necessary parameters: 
          'n_vertex'
          'edge_list'
          'neighbours_threshold'
          'similarity_threshold'
        Returns:
          'labels', 'clusters' and 'execution time'

      - compute_greedy_newman
        Necessary parameters: 
          'n_vertex'
          'edge_list'
        Returns:
          'labels', 'clusters' and 'execution time'

      - compute_walktrap
        Necessary parameters: 
          'n_vertex'
          'edge_list'
        Additional parameters (if not given - choosen automatically):
          'n_clusters'
        Returns:
          'labels', 'clusters' and 'execution time'

      - compute_lpa
        Necessary parameters: 
          'n_vertex'
          'edge_list'
        Returns:
          'labels', 'clusters' and 'execution time'

      - compute_cfinder
        Necessary parameters: 
          'n_vertex'
          'edge_list'
          'clique_size'
        Returns:
          'labels', 'clusters' and 'execution time'

      - compute_clauset_newman
        Necessary parameters: 
          'n_vertex'
          'edge_list'
          'n_clusters'
        Returns:
          'labels', 'clusters' and 'execution time'

      - compute_bigclam
        Necessary parameters: 
          'n_vertex'
          'edge_list'
          'n_clusters'
        Returns:
          'labels', 'clusters' and 'execution time'

---------------------------------------------------------------------------------------------------
    *bench.py

      - make_experiment
        Necessary parameters: 
          'algorithms'
          'datasets'
        Additional paraameters:
          'n_clusters'
          'neighbours_threshold'
          'similarity_threshold'
          'n_steps'
          'clique_size'
        Returns:
          'result'

      - make_optimal_experiment
        Necessary parameters: 
          'algorithms'
          'datasets'
        (Additional parameters will be chosen automatically)
        Returns:
          'result'


---------------------------------------------------------------------------------------------------
    *cluter_metrics.py

      - compute_nmi(labels_true, labels_pred)
      - compute_ars(labels_true, labels_pred)
      - Ñompute_recall(clusters_true, clusters_pred)
      - compute_precision(clusters_true, clusters_pred)
      - compute_avg_f1(clusters_true, clusters_pred)
      - compute_modularity(labels_pred, edge_list)
      - compute_overlapping_modularity(clusters_pred, n_vertex, edge_list)
      - compute_ratio_cut(labels_pred, clusters_pred, edge_list)
      - compute_normalized_cut(labels_pred, clusters_pred, edge_list)

---------------------------------------------------------------------------------------------------
    *get_parameters.py

      - get_optimal_parameters
        Parameters: 'dataset', recompute=False (always!)
        Returns: 'parameters' --- dict with keys 'n_clusters', 'neighbours_threshold', 'similarity_threshold', 'n_steps', 'clique_size'.
        Description: Optimal value of corresponding parameter for given dataset.

---------------------------------------------------------------------------------------------------
    *transform_functions.py

      - compute_adjacency_matrix
        Parameters: 'n_vertex', 'edge_list'
        Returns: 'adjacency_matrix'

      - compute_csr_form
        Parameters: 'edge_list'
        Returns: 'rows', 'columns', 'weights' for using scipy.sparse library

      - compute_networkx_form
        Parameters: 'n_vertex', 'edge_list'
        Returns: networkx.graph() for using networkx algorithms

      - compute_igraph_form
        Parameters: 'n_vertex', 'edge_list'
        Returns: igraph.Graph() and list of edge weights for using igraph algorithms

      - compute_normal_labels
        Parameters: 'labels'
        Returns: 'normal_labels'
        Example: labels = [1.5, 0, 1.5, 1, 1, 1.5] -> normal_labels = [0, 1, 0, 2, 2, 0]

      - compute_labels_from_clusters
        Parameters: 'n_vertex', 'clusters'
        Returns: 'labels'
        Example: n_vertex = 6, clusters = [[0, 2, 3], [1, 5], [4]] -> labels = [0, 1, 0, 0, 2, 1]
        (Possible only for non-overlapping clusters)

      - compute_clusters_from_labels
      	Parameters: 'labels'
      	Returns: 'clusters'
      	Example: labels = [0, 1, 0, 0, 2, 1] -> clusters = [[0, 2, 3], [1, 5], [4]]

      - compute_amount_of_communities_from_labels
        Parameters: 'labels'
        Return: 'n_clusters'

      - compute_amount_of_communities_from_clusters
        Parameters: 'clusters'
        Return: 'n_clusters'

      - extract_biggest_component
      	Parameters: 'filename'
      	Returns: nothing
      	Description: Checks if graph described in 'filename' is fully connected. If not, extracts biggest connected component and write it in 'fileame_new'.
      	             Besides, if file with answer exists, extracts corresponding labels and write it in 'filename_new_labels' or 'filename_new_clusters'

---------------------------------------------------------------------------------------------------